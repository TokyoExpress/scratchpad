{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Backpropagation\r\n",
    "\r\n",
    "Okay, let's get started. I'm doing this because a year into my career as a machine learning engineer, I was asked to code backpropagation for a simple neural network from scratch and failed miserably. So I thought it might be good to dive back into the roots and really understand what's going on, before I go back to using transformers and convolutions and SwiGLUs and whatever else is going on in the industry these days. If you're like me and got into all this without any solid educational foundation in deep learning from a prestigious institution, then feel free to follow along. But enough about me. We're here to do some math and coding. Hopefully not too much math.\r\n",
    "\r\n",
    "## 1.1 Math\r\n",
    "\r\n",
    "Ah dang. Well, whatever. The intuition of backpropagation is quite simple. We have a function $f(x) = y$ and we'd like to minimize the loss function $L(y)$. Consider a simple example where $f(x)$ is a neural network with 2 linear layers, with the sigmoid activation after each one. Thus:\r\n",
    "\r\n",
    "$f(x) = S(L_2(S(L_1(x)))) = S((S(XW_1 + b_1))W_2 + b_2))$\r\n",
    "\r\n",
    "To update the parameters $W_1, W_2, b_1$, and $b_2$, we need to calculate the loss gradient with respect to each of them, which is the current rate of change of the loss with respect to each specific parameter. Moving each parameter in the opposite direction of these gradients will cause the loss to decrease.\r\n",
    "\r\n",
    "We can obtain these gradients by taking the original loss gradient with respect to the output and backpropagating it through the layers, multiplying by each component as per the chain rule to get the value we need. For example, if we want the loss gradient with respect to $b_2$, we must obtain:\r\n",
    "\r\n",
    "$\\frac{dL}{db_2} = \\frac{dL}{dS(L_2(S(L_1(x))))} * \\frac{dS(L_2(S(L_1(x))))}{dL_2(S(L_1(x)))} * \\frac{dL_2(S(L_1(x)))}{db_2}$\r\n",
    "\r\n",
    "Essentially, we need to use the chain rule to unravel the neural network function until we have $L_2(S(L_1(x))) = (S(XW_1 + b_1))W_2 + b_2$, the part of the function that directly involves $b_2$.\r\n",
    "\r\n",
    "Similarly, if we want it with respect to $b_1$, the formula is:\r\n",
    "\r\n",
    "$\\frac{dL}{db_1} = \\frac{dL}{dS(L_2(S(L_1(x))))} * \\frac{dS(L_2(S(L_1(x))))}{dL_2(S(L_1(x)))} * \\frac{dL_2(S(L_1(x)))}{dS(L_1(x))} * \\frac{dS(L_1(x))}{dL_1(x)} * \\frac{dL_1(x)}{db_1}$\r\n",
    "\r\n",
    "As you can see, the two gradients share some computation. Moreover, the expression $\\frac{dS(L_2(S(L_1(x))))}{dL_2(S(L_1(x)))}$ in the equation above can only be calculated using the inputs and outputs of layer 2: thus for layer 1 to be able to obtain the gradients for $W_1$ and $b_1$, it must receive a gradient from layer 2 that has already processed some of the computation, namely:\r\n",
    "\r\n",
    "$grad = \\frac{dL}{dS(L_2(S(L_1(x))))} * \\frac{dS(L_2(S(L_1(x))))}{dL_2(S(L_1(x)))} * \\frac{dL_2(S(L_1(x)))}{dS(L_1(x))}$\r\n",
    "\r\n",
    "The gradients for layer 1 can then be obtained by simply multiplying on top of it like so:\r\n",
    "\r\n",
    "$\\frac{dL}{db_1} = grad * \\frac{dS(L_1(x))}{dL_1(x)} * \\frac{dL_1(x)}{db_1}$\r\n",
    "\r\n",
    "As such, the loss gradient must be propagated backwards through all the layers, each one performing the computation required for the next layer back.\r\n",
    "\r\n",
    "## 1.2 Implementation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}